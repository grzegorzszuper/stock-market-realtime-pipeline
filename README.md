# ğŸ“Š Stock Market Real-Time Data Analytics Pipeline (AWS + Terraform)

Serverless pipeline do pobierania, przetwarzania i analizowania danych gieÅ‚dowych w czasie rzeczywistym.  
**PrzepÅ‚yw danych:** API â†’ Kinesis â†’ Lambda (ingest) â†’ S3 (RAW) + DynamoDB (CLEAN) â†’ Glue/Athena â†’ Lambda (trends) â†’ SNS (e-mail).

---

## ğŸ§­ Architektura (skrÃ³t)

1. **Producer (Python, `producer_api.py`)** â€“ pobiera ceny z API (yfinance) i wysyÅ‚a je do **Kinesis Data Streams**.  
2. **Lambda #1 â€“ ingest** â€“ przetwarza rekordy i zapisuje:
   - **RAW â†’ S3** (do analizy/archiwum),
   - **CLEAN â†’ DynamoDB** (do szybkich odczytÃ³w i trendÃ³w).
3. **AWS Glue Crawler** â€“ kataloguje dane RAW w **Glue Data Catalog**.  
4. **Athena** â€“ pozwala wykonywaÄ‡ zapytania SQL na danych w S3, wyniki zapisuje do bucketu *results*.  
5. **EventBridge** â€“ co X minut uruchamia **Lambda #2 â€“ trends**.  
6. **Lambda #2 â€“ trends** â€“ liczy sygnaÅ‚y (SMA/threshold) na danych z DynamoDB i publikuje do **SNS**.  
7. **SNS** â€“ wysyÅ‚a e-maile z alertami gieÅ‚dowymi lub o braku danych.

---

## ğŸ“‚ Struktura projektu
```txt
ğŸ“ Stock-Market-Realtime-Pipeline/
â”œâ”€â”€ ğŸ“ infra/                 # Terraform â€“ caÅ‚a infrastruktura AWS
â”‚   â”œâ”€â”€ athena.tf
â”‚   â”œâ”€â”€ dynamodb.tf
â”‚   â”œâ”€â”€ eventbridge.tf
â”‚   â”œâ”€â”€ glue.tf
â”‚   â”œâ”€â”€ iam.tf
â”‚   â”œâ”€â”€ kinesis.tf
â”‚   â”œâ”€â”€ lambda.tf
â”‚   â”œâ”€â”€ monitoring.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”œâ”€â”€ provider.tf
â”‚   â”œâ”€â”€ s3.tf
â”‚   â”œâ”€â”€ sns.tf
â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â””â”€â”€ variables.tf
â”‚
â”œâ”€â”€ ğŸ“ lambda/                # Kody funkcji AWS Lambda
â”‚   â”œâ”€â”€ ingest_handler.py     # przetwarzanie danych z Kinesis â†’ S3 + DynamoDB
â”‚   â””â”€â”€ trends_handler.py     # analiza trendÃ³w + powiadomienia
â”‚
â”œâ”€â”€ ğŸ“ tools/                 # Skrypty pomocnicze / symulacja danych gieÅ‚dowych
â”‚   â”œâ”€â”€ producer.py           # generuje przykÅ‚adowe dane stock i wysyÅ‚a do Kinesis
â”‚   â””â”€â”€ producer_api.py       # wariant do pobierania danych np. z API (do rozbudowy)
â”‚
â”œâ”€â”€ ğŸ“ screens/               # Zrzuty ekranu architektury i dziaÅ‚ania systemu
â”‚   â””â”€â”€ (screenshots .png)    # np. Glue Crawler, Athena Query, DynamoDB itd.
â”‚
â”œâ”€â”€ out.json                  # przykÅ‚adowy wynik / output testowy
â”œâ”€â”€ payload.json              # przykÅ‚adowy event wejÅ›ciowy do testÃ³w Lambdy
â””â”€â”€ README.md                 # dokumentacja projektu
```
---

## ğŸš€ Uruchomienie (Quick Start)

### 1. Deploy infrastruktury
```bash
cd infra
terraform init -upgrade
terraform apply -auto-approve
```
Po zakoÅ„czeniu zapisz wartoÅ›ci z outputs.tf (nazwa strumienia Kinesis, buckety, topic SNS, nazwy Lambd).

### 2. PotwierdÅº subskrypcjÄ™ e-mail (SNS)

SprawdÅº skrzynkÄ™ pocztowÄ… i kliknij Confirm subscription. Status w SNS = Confirmed.

 ### 3. Odpal producenta danych (API)

$env:AWS_REGION="eu-west-3"
$env:KINESIS_STREAM="<kinesis_stream_name_z_outputs>"
python tools\producer_api.py

Alternatywnie: tools/producer.py (syntetyczne trendy dla szybszych testÃ³w).

âœ… Test end-to-end (ze screenami)

### 1. S3 RAW
![S3 RAW](./screens/s3_raw.png)

### 2. DynamoDB
![DynamoDB](./screens/dynamodb.png)

### 3. Glue + Athena
**Glue Crawler â€“ status Completed**  
![Glue Crawler](./screens/glue_crawler.png)

**Athena â€“ baza `stock_raw_db`**  
![Athena Show Tables](./screens/athena_show_tables.png)

![Athena Query](./screens/athena_query.png)

### 4. Lambda + CloudWatch
![Lambda Ingest](./screens/lambda_ingest.png)
![CloudWatch Ingest](./screens/cw_ingest.png)
![CloudWatch Ingest2](./screens/cw_ingest2.png)

![Lambda Trends](./screens/lambda_trends.png)
![CloudWatch Trends](./screens/cw_trends.png)
![CloudWatch Trends2](./screens/cw_trends2.png)

### 5. Powiadomienia SNS
![SNS Email](./screens/sns_email.png)
![Alarm SNS Email](./screens/alarm_sns_email.png)


ğŸ§  Logika alertÃ³w (Lambda trends)

ReguÅ‚y:

BUY: spadek â‰¤ THRESH_PCT i last < SMA_WINDOW

SELL: wzrost â‰¥ THRESH_PCT i last > SMA_WINDOW

Filtr szumu: |last âˆ’ SMA| / SMA â‰¥ EPS_PCT

Warunki minimalne: MIN_POINTS rekordÃ³w oraz porÃ³wnanie do LOOKBACK_POINTS wstecz

Zmienne Å›rodowiskowe (Configuration â†’ Environment variables):

![Environment Variables](/screens/env_variables.png)

ğŸ§ª Health-check (CLI)

# S3 RAW â€“ czy nowe pliki dochodzÄ…?
```bash
aws s3 ls s3://<raw_bucket>/raw/ --region eu-west-3

# DDB â€“ szybki podglÄ…d
aws dynamodb scan --table-name StockCleanedData --region eu-west-3 --max-items 5

# Athena â€“ szybkie query
aws athena start-query-execution \
  --query-string "SELECT count(*) FROM stock_raw_db.raw;" \
  --work-group analytics \
  --result-configuration OutputLocation=s3://<athena_results_bucket>/ \
  --region eu-west-3

# Trends â€“ rÄ™czne uruchomienie Lambdy
aws lambda invoke --function-name <trends_lambda_name> --region eu-west-3 out.json

# SNS â€“ test publikacji
aws sns publish --topic-arn <sns_topic_arn> --subject "Test" --message "hello" --region eu-west-3
```
ğŸ NajczÄ™stsze problemy

Brak e-maila
SprawdÅº: 1) subskrypcja SNS = Confirmed, 2) logi w CloudWatch, 3) rÄ™czne sns publish.

TABLE_NOT_FOUND w Athenie
Uruchom crawlera lub: MSCK REPAIR TABLE stock_raw_db.raw;.

Tylko 50 wpisÃ³w w DDB
Celowe limitowanie w query â€“ sprawdÅº unikalnoÅ›Ä‡ timestamp (mikrosekundy).

ResourceNotFoundException przy PutRecord
ZÅ‚a nazwa strumienia â€“ uÅ¼yj wartoÅ›ci z Terraform outputs.

ğŸ’° Koszty

Kinesis: ok. $0.015 / shard / h

DynamoDB: on-demand (za Å¼Ä…dania)

S3: niski koszt (maÅ‚e pliki)

Lambda, EventBridge, Glue: pay-per-use

SNS: e-maile w darmowym limicie

Aby wyÅ‚Ä…czyÄ‡ infrastrukturÄ™:
```bash
cd infra
terraform destroy -auto-approve
```
ğŸ‘¤ Autor
Grzegorz Szuper

